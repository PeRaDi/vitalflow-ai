{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c12c8b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /root/miniconda3/envs/ai/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/ai/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /root/miniconda3/envs/ai/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: torch in /root/miniconda3/envs/ai/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/ai/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fa86035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!> Selecting GPU as main device <!>\n",
      "<!> Using: NVIDIA GeForce GTX 1050<!>\n"
     ]
    }
   ],
   "source": [
    "# check torch gpu\n",
    "import torch\n",
    "\n",
    "device = None\n",
    "\n",
    "print(\"<!> Selecting GPU as main device <!>\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"<!> Using: \" + torch.cuda.get_device_name(0) + \"<!>\")\n",
    "else:\n",
    "    print(\"<!> No GPU available <!>\")\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c21baa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!> Loading train dataframe <!>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"<!> Loading train dataframe <!>\")\n",
    "train_df = pd.read_csv('/root/test/train_transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60a07509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i+seq_length])\n",
    "        targets.append(data[i+seq_length])\n",
    "    return np.array(sequences), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "002a570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!> Generating series <!>\n",
      "<!> Normalizing data <!>\n",
      "<!> Generating sequences data for 30 days <!>\n",
      "<!> Generating PyTorch tensors <!>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(\"<!> Generating series <!>\")\n",
    "# Extract demand for product 2\n",
    "train_series = train_df[str(2)].values.reshape(-1, 1)\n",
    "\n",
    "print(\"<!> Normalizing data <!>\")\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "train_series = scaler.fit_transform(train_series)\n",
    "\n",
    "print(\"<!> Generating sequences data for 30 days <!>\")\n",
    "SEQ_LENGTH = 30 \n",
    "X_train, y_train = create_sequences(train_series, SEQ_LENGTH)\n",
    "\n",
    "print(\"<!> Generating PyTorch tensors <!>\")\n",
    "# Convert to PyTorch tensors and move to device\n",
    "X_train, y_train = torch.tensor(X_train, dtype=torch.float32).to(device), torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create Dataset class\n",
    "class DemandDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = DemandDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "017e57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Bidirectional LSTM Model with Dropout\n",
    "class BiLSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_rate=0.2):\n",
    "        super(BiLSTMPredictor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, bidirectional=True, dropout=dropout_rate)\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, 64)  # Bidirectional => hidden_size * 2\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)  \n",
    "        last_step_output = lstm_out[:, -1, :]  # Take last time step\n",
    "        x = self.fc1(last_step_output)\n",
    "        x = self.relu(x)\n",
    "        return self.fc2(x)  # Final output layer\n",
    "\n",
    "# Model setup\n",
    "INPUT_SIZE = 1  # Single feature (demand)\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 3\n",
    "OUTPUT_SIZE = 1\n",
    "DROPOUT_RATE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22b3d850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!> Training <!>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0471\n",
      "Epoch 2, Loss: 0.0148\n",
      "Epoch 3, Loss: 0.0130\n",
      "Epoch 4, Loss: 0.0144\n",
      "Epoch 5, Loss: 0.0129\n",
      "Epoch 6, Loss: 0.0135\n",
      "Epoch 7, Loss: 0.0137\n",
      "Epoch 8, Loss: 0.0128\n",
      "Epoch 9, Loss: 0.0130\n",
      "Epoch 10, Loss: 0.0128\n",
      "Epoch 11, Loss: 0.0130\n",
      "Epoch 12, Loss: 0.0125\n",
      "Epoch 13, Loss: 0.0127\n",
      "Epoch 14, Loss: 0.0119\n",
      "Epoch 15, Loss: 0.0084\n",
      "Epoch 16, Loss: 0.0073\n",
      "Epoch 17, Loss: 0.0051\n",
      "Epoch 18, Loss: 0.0034\n",
      "Epoch 19, Loss: 0.0028\n",
      "Epoch 20, Loss: 0.0029\n",
      "Epoch 21, Loss: 0.0028\n",
      "Epoch 22, Loss: 0.0027\n",
      "Epoch 23, Loss: 0.0026\n",
      "Epoch 24, Loss: 0.0031\n",
      "Epoch 25, Loss: 0.0022\n",
      "Epoch 26, Loss: 0.0021\n",
      "Epoch 27, Loss: 0.0022\n",
      "Epoch 28, Loss: 0.0024\n",
      "Epoch 29, Loss: 0.0025\n",
      "Epoch 30, Loss: 0.0021\n",
      "Epoch 31, Loss: 0.0022\n",
      "Epoch 32, Loss: 0.0022\n",
      "Epoch 33, Loss: 0.0030\n",
      "Epoch 34, Loss: 0.0021\n",
      "Epoch 35, Loss: 0.0021\n",
      "Epoch 36, Loss: 0.0021\n",
      "Epoch 37, Loss: 0.0020\n",
      "Epoch 38, Loss: 0.0021\n",
      "Epoch 39, Loss: 0.0020\n",
      "Epoch 40, Loss: 0.0019\n",
      "Epoch 41, Loss: 0.0020\n",
      "Epoch 42, Loss: 0.0025\n",
      "Epoch 43, Loss: 0.0020\n",
      "Epoch 44, Loss: 0.0019\n",
      "Epoch 45, Loss: 0.0021\n",
      "Epoch 46, Loss: 0.0020\n",
      "Epoch 47, Loss: 0.0022\n",
      "Epoch 48, Loss: 0.0020\n",
      "Epoch 49, Loss: 0.0023\n",
      "Epoch 50, Loss: 0.0039\n",
      "<!> Done <!>\n"
     ]
    }
   ],
   "source": [
    "print(\"<!> Training <!>\")\n",
    "\n",
    "model = BiLSTMPredictor(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE, DROPOUT_RATE).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "EPOCHS = 50\n",
    "\n",
    "def train_model():\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move batch to device\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "train_model()\n",
    "\n",
    "print(\"<!> Done <!>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a79d89f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!> Saving model <!>\n"
     ]
    }
   ],
   "source": [
    "print(\"<!> Saving model <!>\")\n",
    "torch.save(model.state_dict(), \"/root/test/lstm_trained_data.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
